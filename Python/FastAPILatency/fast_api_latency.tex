\documentclass[12pt,letterpaper]{article}
\usepackage[utf8]{inputenc}

% Ajustamos los márgenes para corregir las advertencias de fancyhdr
\usepackage[letterpaper, margin=1in, bottom=3in, top=2.2in]{geometry}

% Cargamos primero el paquete fancyhdr
\usepackage{fancyhdr}
% Corregimos los parámetros headheight y footskip
\setlength{\headheight}{15pt} % Al menos 14.49998pt según la advertencia
\setlength{\footskip}{72pt}   % Al menos 71.60547pt según la advertencia

\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{anyfontsize}
\usepackage{graphicx}
\usepackage{tikz} % Necesario para los elementos gráficos
\usepackage{listings} % Para resaltado de sintaxis
\usepackage{sourcesanspro}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{fontawesome5}
\usepackage{titlesec}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{mdframed} % Para marcos más estables
\usepackage{qrcode} % Paquete para generar códigos QR
\usepackage{eso-pic}
\usepackage{float}

\floatplacement{figure}{H}

% Cargar tikz y la biblioteca de cajitas para mdframed
\usetikzlibrary{calc,shapes,positioning}

% IMPORTANT: Force the text color to be white for the entire document
\AtBeginDocument{\color{primaryColor}}

% Colors updated with better contrast
\definecolor{myblue}{cmyk}{1.0,0.8,0.05,0.20}
\definecolor{bgColor}{RGB}{15, 22, 36}  % Very dark blue, almost black background
\definecolor{primaryColor}{RGB}{255, 255, 255}  % White text - full white for better contrast
\definecolor{accentColor}{RGB}{255, 212, 59}  % Python Yellow
\definecolor{pythonBlue}{RGB}{120, 180, 255}  % Azul Python más claro para mejor contraste
\definecolor{secondaryColor}{RGB}{220, 230, 240}  % Lighter blue-gray for better contrast
\definecolor{terminalBg}{RGB}{22, 22, 22}  % Terminal background remains dark
\definecolor{terminalFrame}{RGB}{40, 40, 40}  % Terminal frame slightly darker
\definecolor{lineNumberColor}{RGB}{100, 100, 100}  % Color más sutil para los números de línea
\definecolor{dividerColor}{RGB}{60, 70, 90}  % Color más sutil para la línea divisoria

% Colores mejorados para el código con mayor contraste
\definecolor{codeTextColor}{RGB}{255, 255, 255}  % Blanco puro para el texto básico
\definecolor{codeKeywordColor}{RGB}{135, 206, 250}  % Azul cielo para palabras clave
\definecolor{codeCommentColor}{RGB}{144, 238, 144}  % Verde claro para comentarios
\definecolor{codeStringColor}{RGB}{255, 215, 135}  % Amarillo para strings
\definecolor{codeMethodColor}{RGB}{255, 160, 122}  % Naranja claro para métodos
\definecolor{codeFunctionColor}{RGB}{255, 215, 0}  % Dorado para funciones
\definecolor{codeNumberColor}{RGB}{255, 255, 150}  % Amarillo claro para números

% Set page background color
\pagecolor{bgColor}

% Hyperref configuration
\hypersetup{
    colorlinks=true,
    linkcolor=accentColor,
    filecolor=accentColor,
    urlcolor=accentColor,
}

% Configuración básica para listings que evita problemas con saltos de página
\lstset{
  language=Python,
  basicstyle=\normalsize\ttfamily\bfseries\color{codeTextColor}, % Tamaño reducido, en blanco y negrita
  backgroundcolor=\color{terminalBg},
  commentstyle=\color{codeCommentColor},
  keywordstyle=\color{codeKeywordColor},
  stringstyle=\color{codeStringColor},
  numberstyle=\color{lineNumberColor}, % Números de línea más sutiles
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4,
  showstringspaces=false,
  frame=none,
  xleftmargin=15pt,
  xrightmargin=0pt,
  aboveskip=10pt,
  belowskip=10pt,
  numbers=left,
  numbersep=8pt,
  extendedchars=true,
  keepspaces=true,
  columns=flexible,
  lineskip=6pt, % Espacio entre líneas ligeramente reducido
  % Keywords de Python (palabras reservadas)
  morekeywords={self, yield, lambda, with, as, from, True, False, None, import, in, for, 
                if, elif, else, while, return, def, class, try, except, finally, raise, 
                break, continue, global, nonlocal, pass, assert, del, yield from},
  % Funciones incorporadas resaltadas de manera distinta
  emph={[2]print,range,sum,int,str,float,list,dict,set,tuple,next,len,type,map,filter,
         reduce,zip,enumerate,sorted,reversed,min,max,open,any,all},
  emphstyle={[2]\color{codeFunctionColor}}
}

% TERMINAL ESTILO MAC MEJORADA CON BOTONES A LA IZQUIERDA Y MENOS ESPACIO SUPERIOR
\newenvironment{macterminal}{%
    \begin{mdframed}[
        linecolor=terminalFrame,
        backgroundcolor=terminalBg,
        roundcorner=5pt,
        skipabove=10pt,
        skipbelow=10pt,
        linewidth=1pt,
        innertopmargin=10pt, % Reducido
        frametitle={%
            \tikz[baseline=(current bounding box.east), outer sep=0pt]{
                \fill[red!80!black] (0,0) circle (5pt);
                \fill[yellow!80!black] (0.7,0) circle (5pt);
                \fill[green!70!black] (1.4,0) circle (5pt);
            }
        },
        frametitlealignment=\raggedright, % Alineado a la izquierda
        frametitleaboveskip=8pt, % Espacio entre el título y el borde superior
        frametitlebelowskip=0pt, % Reducir el espacio entre el título y el contenido
    ]
    % No necesitamos más espacio vertical aquí
}{%
    \end{mdframed}%
}

% Utilities
\newcommand{\verspace}{\vspace{10pt}}

% Section styling - Esquema más elegante y mejorado contraste
\titleformat{\section}
  {\LARGE\bfseries\color{primaryColor}} % Secciones principales en blanco para mejor contraste y más grandes
  {\thesection. }
  {0pt}
  {}
  []

\titleformat{\subsection}
  {\Large\bfseries\color{accentColor}} % Subsecciones en amarillo Python y más grandes
  {\thesubsection. }
  {0pt}
  {}
  []

\titleformat{\subsubsection}
  {\large\bfseries\color{pythonBlue}} % Subsubsecciones en azul Python más claro y más grandes
  {\thesubsubsection. }
  {0pt}
  {}
  []

% Spacing for sections
\titlespacing*{\section}{0pt}{20pt}{10pt}
\titlespacing*{\subsection}{0pt}{15pt}{7pt}
\titlespacing*{\subsubsection}{0pt}{10pt}{5pt}

% Configure header and footer
\pagestyle{fancy}
\fancyhf{}

% Crear un encabezado elegante para todas las páginas (excepto la portada)
\fancyhead[L]{
    \begin{tikzpicture}[remember picture, overlay]
        % Rectángulo de fondo para la sección Python
        \fill[pythonBlue, rounded corners=3pt] (0,0) rectangle (2.2cm,0.7cm);
        % Texto Python
        \node[text=primaryColor, font=\bfseries] at (1.1cm,0.35cm) {PYTHON};
        
        % Pequeño separador
        \fill[secondaryColor] (2.35cm,0.1cm) rectangle (2.40cm,0.6cm);
        
        % Texto Concurrency & Parallelism con el color de acento
        \node[text=accentColor, font=\bfseries, anchor=west] at (2.35cm,0.35cm) {CONCURRENCY \& PARALLELISM};
    \end{tikzpicture}
}

% Línea de encabezado
\renewcommand{\headrulewidth}{0pt}


% Configure footer with profile info
\fancyfoot[C]{
    \vspace*{0.2cm}
    \noindent
    \begin{minipage}{\textwidth}
        \begin{flushleft}
            % Profile image placeholder with TikZ
            \raisebox{0.7cm}{
            \begin{tikzpicture}[baseline]
                \path[fill=bgColor] (0,0) circle (0.8cm);
                \clip (0,0) circle (0.8cm);
                \node at (0,0) {
                    % Placeholder for profile image
                    \includegraphics[width=1.6cm,height=1.6cm]{../../Images/profile-image.jpeg}
                };
            \end{tikzpicture}
            }
            \begin{minipage}[b]{0.8\textwidth}
                % Name
                {\large\bfseries\color{primaryColor}Alejandro Sánchez Yalí}
                
                % Professional description
                \par\vspace{1pt}
                {\small\color{secondaryColor}Software Developer | AI \& Blockchain Enthusiast}
                
                % Contact
                \par\vspace{1pt}
                {\small\color{accentColor}\faGlobe\hspace{5pt}\color{secondaryColor}www.asanchezyali.com}
            \end{minipage}
        \end{flushleft}
        \vspace{8pt} % Space at bottom
    \end{minipage}
}

% Estilo para la portada (sin encabezado ni pie de página)
\fancypagestyle{plain}{
    \fancyhf{}
    \renewcommand{\headrulewidth}{0pt}
    \renewcommand{\footrulewidth}{0pt}
}

% Bullet styling for lists
\renewcommand{\labelitemi}{\textcolor{accentColor}{$\bullet$}} % Primer nivel de viñetas en amarillo (mejor contraste)
\renewcommand{\labelitemii}{\textcolor{pythonBlue}{$\circ$}} % Segundo nivel de viñetas en azul

% Aumentar globalmente el tamaño de texto un 20%
\usepackage{relsize}
\AtBeginDocument{\relsize{1}} % Incrementa la fuente en aproximadamente un 20%

% Comando simplificado para la etiqueta Python
\newcommand{\languagetag}[1]{
    \begin{tikzpicture}[baseline]
        \node[fill=pythonBlue, text=primaryColor, rounded corners=5pt, inner sep=7pt] {
            {\normalsize\textbf{#1}}
        };
    \end{tikzpicture}
}

% Luego, define un comando para colocar la imagen de fondo en la primera página
\newcommand{\BackgroundPic}{%
    \put(0,0){%
        \begin{tikzpicture}[remember picture, overlay]
            % Coloca la imagen de fondo que cubra toda la página
            \node[inner sep=0pt] at (current page.center) {
                \includegraphics[width=\paperwidth,height=\paperheight,keepaspectratio=false]{../../Images/Futuristic Cybersecurity Analyst.jpeg}
            };
            
            % Agrega una capa semitransparente oscura sobre la imagen
            \fill[black, opacity=0.7] (current page.south west) rectangle (current page.north east);
        \end{tikzpicture}%
    }%
}

% Alternativa usando una versión modificada de la URL
\newcommand{\elegantqr}[2]{
    \qrcode[height=2.5cm]{#1}
    \\[0.1cm]
    {\hspace{0.2cm}\color{primaryColor}\small #2\par}
}

% Definir el título personalizado con alineación exacta para todos los elementos
\newcommand{\titlepagecontents}{%
    \AddToShipoutPicture*{\BackgroundPic}
    \vspace*{2cm}
    % Asegurar que todos los elementos estén alineados a la izquierda
    \begin{flushleft}
    \languagetag{Python}\\[0.4cm]
    {\fontsize{48}{52}\bfseries\color{primaryColor}FastAPI \color{accentColor}Latency\par}
    \vspace{0.3cm}
    {\fontsize{18}{52}\color{secondaryColor}Understanding and Optimizing Response Times\par}
    \vspace{0.3cm}
    {\color{secondaryColor}\today\par}
    \vspace{2cm}
    % El QR se alineará a la izquierda aunque internamente esté centrado
    \elegantqr{https://github.com/asanchezyali/social-media-posts/tree/main/Python/FastAPILatency}{Source Code}
    \end{flushleft}
}

% En la página del título, aplicar el contenido sin márgenes adicionales
\makeatletter
\renewcommand{\maketitle}{%
    \begin{titlepage}
    \setlength{\parindent}{0pt}
    \setlength{\leftskip}{0pt}
    \titlepagecontents
    \end{titlepage}
}
\makeatother

\newcommand{\finalpagecontents}{%
    \AddToShipoutPicture*{\BackgroundPic}
    \vspace*{3cm}
    % Left-aligned elements with EXACT same structure as title page
    \begin{flushleft}
    \languagetag{Feedback}\\[0.4cm]
    {\fontsize{46}{52}\bfseries\color{primaryColor}Found this \color{accentColor}helpful?\par}
    \vspace{0.3cm}
    {\fontsize{18}{52}\color{secondaryColor}Save, comment and share\par}  
    \vspace{0.3cm}
    {\color{secondaryColor}\today\par}
    \end{flushleft}
}

\begin{document}
\setlength{\parindent}{0pt}
\color{primaryColor} % Explicitly set text color to white for the entire document

\begin{titlepage}
    % Eliminamos todos los espacios adicionales para asegurar la alineación
    \titlepagecontents
\end{titlepage}

\section{Introduction to API Performance}

In modern web development, speed and efficiency are crucial. Understanding fundamental concepts like latency and response time is essential to ensure APIs are scalable and provide an optimal user experience. This article uses FastAPI as a practical example to demonstrate these concepts, but the principles of latency, response time, and percentiles are applicable to all API systems, regardless of the technology used.

\subsection{Latency vs Response Time: Understanding the Difference}

Although often used interchangeably, \textbf{\textcolor{accentColor}{latency}} and \textbf{\textcolor{accentColor}{response time}} are distinct concepts:

\begin{itemize}
    \item \textbf{\textcolor{pythonBlue}{Response Time:}} What the client perceives—includes request processing time (service time), network delays, and queue wait times.
    \item \textbf{\textcolor{pythonBlue}{Latency:}} The duration a request spends waiting to be processed—the time it remains latent before processing begins.
\end{itemize}

\subsection{Measuring Performance: Beyond Averages}

When evaluating API performance, average response time is commonly reported. However, averages are not ideal metrics for understanding "typical" system behavior because they don't reflect real user experience.

Using \textbf{\textcolor{accentColor}{percentiles}} provides a more accurate picture:

\begin{itemize}
    \item \textbf{\textcolor{pythonBlue}{50th Percentile (p50) or Median:}} Half of requests complete in less time, half take longer.
    \item \textbf{\textcolor{pythonBlue}{High Percentiles}} like p95, p99, and p999: Reveal how bad your outliers are and how they affect a small but significant percentage of users.
\end{itemize}

High percentiles, also known as "tail latencies," are crucial because they directly affect user experience. For example, Amazon describes response time requirements for internal services in terms of the 99.9th percentile, even though it affects only 1 in 1,000 requests, as these users often have the most valuable accounts.

\section{Performance Monitoring with FastAPI}

Let's build a small service with FastAPI and simulate load to analyze its behavior. Our goal is to measure and visualize different response time percentiles.

\subsection{Creating a FastAPI Application}

First, we'll create a simple API with different endpoints that simulate various processing times:

\begin{macterminal}
\begin{lstlisting}
# api_server.py
import asyncio
import random
import time
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Latency Demo API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """Fast endpoint with consistent response time"""
    return {"message": "Latency demonstration API"}

@app.get("/fast")
async def fast_endpoint():
    """Endpoint with fast response (10-30ms)"""
    await asyncio.sleep(random.uniform(0.01, 0.03))
    return {"response_type": "fast"}

@app.get("/medium")
async def medium_endpoint():
    """Endpoint with medium response time (50-150ms)"""
    await asyncio.sleep(random.uniform(0.05, 0.15))
    return {"response_type": "medium"}

@app.get("/slow")
async def slow_endpoint():
    """Endpoint with slow response time (200-500ms)"""
    await asyncio.sleep(random.uniform(0.2, 0.5))
    return {"response_type": "slow"}

@app.get("/variable")
async def variable_endpoint():
    """
    Endpoint with variable response time:
    - 80% of requests: fast (10-50ms)
    - 15% of requests: medium (100-300ms)
    - 5% of requests: very slow (500-1500ms)
    """
    random_value = random.random()
    
    if random_value < 0.8:
        await asyncio.sleep(random.uniform(0.01, 0.05))
        category = "fast (80%)"
    elif random_value < 0.95:
        await asyncio.sleep(random.uniform(0.1, 0.3))
        category = "medium (15%)"
    else:
        await asyncio.sleep(random.uniform(0.5, 1.5))
        category = "very slow (5%)"
    
    return {"response_type": "variable", "category": category}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api_server:app", host="0.0.0.0", port=8000, reload=True)
\end{lstlisting}
\end{macterminal}

\subsection{Creating a Load Testing Agent}

Now, let's create an agent that performs multiple requests to our API and collects performance data:

\begin{macterminal}
\begin{lstlisting}
# load_tester.py
import asyncio
import time
import statistics
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict

class LoadTester:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.endpoints = {
            "fast": "/fast",
            "medium": "/medium",
            "slow": "/slow",
            "variable": "/variable"
        }
        self.results = defaultdict(list)
    
    async def make_request(self, session, endpoint):
        """Makes an HTTP request and measures response time"""
        url = f"{self.base_url}{self.endpoints[endpoint]}"
        start_time = time.time()
        
        try:
            async with session.get(url) as response:
                await response.json()
                response_time = (time.time() - start_time) * 1000
                self.results[endpoint].append(response_time)
                return response_time
        except Exception as e:
            print(f"Error in request to {url}: {e}")
            return None
    
    async def generate_load(self, endpoint, num_requests, concurrency):
        """Generates load for a specific endpoint"""
        async with aiohttp.ClientSession() as session:
            tasks = []
            for _ in range(num_requests):
                tasks.append(self.make_request(session, endpoint))
                if len(tasks) >= concurrency:
                    await asyncio.gather(*tasks)
                    tasks = []
            
            if tasks:
                await asyncio.gather(*tasks)
    
    def calculate_percentiles(self, endpoint):
        """Calculates percentiles for response times"""
        if not self.results[endpoint]:
            return {}
        
        data = sorted(self.results[endpoint])
        return {
            "min": min(data),
            "p50": statistics.median(data),
            "p90": np.percentile(data, 90),
            "p95": np.percentile(data, 95),
            "p99": np.percentile(data, 99),
            "p999": np.percentile(data, 99.9) if len(data) >= 1000 else None,
            "max": max(data),
            "mean": statistics.mean(data),
            "stdev": statistics.stdev(data) if len(data) > 1 else 0
        }
    
    def plot_results(self):
        """Generates charts to visualize the results"""
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14))
        
        endpoints = list(self.results.keys())
        metrics = ["p50", "p90", "p95", "p99"]
        
        x = np.arange(len(endpoints))
        width = 0.2
        
        for i, metric in enumerate(metrics):
            values = [self.calculate_percentiles(ep)[metric] for ep in endpoints]
            ax1.bar(x + i*width, values, width, label=f'{metric}')
        
        ax1.set_ylabel('Response Time (ms)')
        ax1.set_title('Response Time Percentiles by Endpoint')
        ax1.set_xticks(x + width * 1.5)
        ax1.set_xticklabels(endpoints)
        ax1.legend()
        ax1.grid(axis='y', linestyle='--', alpha=0.7)
        
        if "variable" in self.results and self.results["variable"]:
            data = self.results["variable"]
            bins = np.logspace(np.log10(min(data)), np.log10(max(data)), 50)
            ax2.hist(data, bins=bins, alpha=0.7, color='green')
            ax2.set_xscale('log')
            ax2.set_title('Response Time Distribution (variable endpoint)')
            ax2.set_xlabel('Response Time (ms) - logarithmic scale')
            ax2.set_ylabel('Number of Requests')
            
            percentiles = self.calculate_percentiles("variable")
            for metric, value in [(k, v) for k, v in percentiles.items() 
                                if k in ["p50", "p90", "p95", "p99"] and v is not None]:
                ax2.axvline(x=value, color='red', linestyle='--', alpha=0.6, 
                           label=f"{metric}: {value:.2f}ms")
            
            ax2.legend()
        
        plt.tight_layout()
        plt.savefig('latency_results.png', dpi=300)
        plt.close()
    
    def print_summary(self):
        """Prints a summary of the results"""
        for endpoint in self.results:
            print(f"\n=== Endpoint: {endpoint} ({len(self.results[endpoint])} requests) ===")
            percentiles = self.calculate_percentiles(endpoint)
            for metric, value in percentiles.items():
                if value is not None:
                    print(f"{metric}: {value:.2f} ms")

async def main():
    tester = LoadTester()
    
    print("Starting load tests...")
    
    for endpoint in tester.endpoints:
        requests = 1000 if endpoint == "variable" else 200
        print(f"Testing endpoint '{endpoint}' with {requests} requests...")
        await tester.generate_load(endpoint, requests, concurrency=50)
    
    tester.print_summary()
    tester.plot_results()
    print("Tests completed. Results saved in 'latency_results.png'")

if __name__ == "__main__":
    asyncio.run(main())

# Output
# Starting load tests...
# Testing endpoint 'fast' with 200 requests...
# Testing endpoint 'medium' with 200 requests...
# Testing endpoint 'slow' with 200 requests...
# Testing endpoint 'variable' with 1000 requests...

# === Endpoint: fast (200 requests) ===
# min: 10.22 ms
# p50: 22.67 ms
# p90: 31.31 ms
# p95: 34.34 ms
# p99: 37.17 ms
# max: 38.25 ms
# mean: 22.79 ms
# stdev: 6.84 ms

# === Endpoint: medium (200 requests) ===
# min: 53.42 ms
# p50: 102.49 ms
# p90: 143.29 ms
# p95: 150.27 ms
# p99: 161.89 ms
# max: 163.58 ms
# mean: 103.06 ms
# stdev: 30.29 ms

# === Endpoint: slow (200 requests) ===
# min: 206.44 ms
# p50: 361.78 ms
# p90: 476.99 ms
# p95: 489.22 ms
# p99: 501.95 ms
# max: 505.02 ms
# mean: 360.42 ms
# stdev: 84.46 ms

# === Endpoint: variable (1000 requests) ===
# min: 11.65 ms
# p50: 38.14 ms
# p90: 239.78 ms
# p95: 297.38 ms
# p99: 1240.78 ms
# p999: 1452.90 ms
# max: 1491.94 ms
# mean: 103.07 ms
# stdev: 213.06 ms
# Tests completed. Results saved in 'latency_results.png'
\end{lstlisting}
\end{macterminal}

\subsection{Running and Analyzing the Results}

To run our experiment:

1. Start the FastAPI server:
\begin{macterminal}
\begin{lstlisting}
python api_server.py
\end{lstlisting}
\end{macterminal}

2. In another terminal, run the load testing agent:
\begin{macterminal}
\begin{lstlisting}
python load_tester.py
\end{lstlisting}
\end{macterminal}

The agent will generate a file called \verb|latency_results.png| with visualizations of the results, and will also print a summary to the console.

{\centering
\includegraphics[width=0.85\textwidth]{../../Images/latency_results.png}\par
}

\section{Analyzing the Results}

The visualizations demonstrate why percentiles provide superior insights for API performance compared to averages:

\subsection{Understanding the Variable Endpoint}

The most revealing insights come from examining the \textbf{\textcolor{accentColor}{variable}} endpoint:

\begin{itemize}
    \item The \textbf{median (p50)} is only 38.14ms, indicating most users receive fast responses.
    \item The \textbf{p90} jumps to 239.78ms, revealing that 10\% of requests experience significantly slower performance.
    \item The \textbf{p95} at 297.38ms shows further degradation for 5\% of requests.
    \item Most critically, the \textbf{p99} at 1240.78ms demonstrates that 1\% of users experience response times over 32 times slower than the median.
    \item The mean (103.07ms) obscures this reality, appearing deceptively moderate despite the extreme outliers.
\end{itemize}

The histogram's logarithmic distribution confirms these observations, showing three distinct clusters corresponding to the programmed response time categories (80\% fast, 15\% medium, 5\% slow).

\subsection{Comparative Analysis Across Endpoints}

Comparing the four endpoints reveals important performance patterns:

\begin{itemize}
    \item \textbf{Predictable endpoints} (fast, medium, slow) show relatively consistent behavior where p99 is only 1.3-1.4 times greater than p50.
    \item The \textbf{variable endpoint} exhibits dramatic tail latency, with p99 being 32.5 times higher than p50.
    \item While the \textbf{mean response time} of the variable endpoint (103.07ms) is nearly identical to the medium endpoint (103.06ms), their performance profiles are entirely different—a fact that would be missed by relying solely on averages.
\end{itemize}

\subsection{Practical Benefits of Percentile-Based Monitoring}

Using percentiles for performance monitoring offers several concrete advantages:

\begin{itemize}
    \item \textbf{Detecting Hidden Issues:} The variable endpoint's mean suggests acceptable performance, while percentiles reveal severe degradation affecting a minority of requests.
    \item \textbf{User-Centric Metrics:} Percentiles directly correspond to user experience—p95 represents what 5\% of your users are experiencing or worse.
    \item \textbf{Early Warning System:} Changes in high percentiles often precede system-wide degradation and can signal emerging problems before they affect most users.
    \item \textbf{SLA Alignment:} Service Level Agreements based on percentiles protect all users, while average-based SLAs may hide systematic failures affecting a subset of users.
    \item \textbf{Infrastructure Sizing:} Understanding tail latency helps properly size infrastructure for peak demands rather than average conditions.
\end{itemize}

The logarithmic histogram of the variable endpoint particularly emphasizes how response times are not normally distributed—they follow a multi-modal distribution with long tails. This pattern is common in real-world systems due to factors like cache misses, garbage collection pauses, or resource contention.

\section{The Tail Latency Amplification Problem}

Imagine that your frontend application needs to make several calls to these endpoints to compose a single page. If a page requires 5 API calls:

\begin{itemize}
    \item With a 5\% probability that each call is slow, the probability that at least one call is slow is:
    \begin{center}
    $1 - (0.95)^5 \approx 23\%$
    \end{center}
\end{itemize}

This means that although only 5\% of individual calls are slow, approximately 23\% of page loads will experience delays. This phenomenon is known as "tail latency amplification."

\section{Conclusion}

When developing and monitoring APIs, it's critical to:

\begin{itemize}
    \item \textbf{\textcolor{pythonBlue}{Measure Percentiles, Not Just Averages:}} High percentiles reveal problems affecting real users that might go unnoticed in means.
    \item \textbf{\textcolor{pythonBlue}{Understand the Complete Distribution:}} Visualize response time histograms to better understand system behavior.
    \item \textbf{\textcolor{pythonBlue}{Consider Tail Latency Amplification:}} Optimizing high percentiles is essential for multi-call user actions.
    \item \textbf{\textcolor{pythonBlue}{Establish SLOs and SLAs Based on Percentiles:}} For example, "p99 must be less than 300ms" is more meaningful than "average time must be less than 100ms."
\end{itemize}

Modern applications must be designed with these principles to provide consistent, high-quality experiences to all users. Future posts will explore techniques like priority queues, circuit breakers, and caching to mitigate tail latency amplification.

\section{References}

\begin{itemize}
    \item Sentry. (2024). \textit{What's the difference between API Latency and API Response Time?}. \href{https://blog.sentry.io/whats-the-difference-between-api-latency-and-api-response-time/#:~:text=API%20latency%20is%20the%20time,request%20and%20return%20the%20result.}{Link}
    \item Catchpoint. \textit{API Performance Monitoring—Key Metrics and Best Practices}. \href{https://www.catchpoint.com/api-monitoring-tools/api-performance-monitoring}{Link}
    \item FastAPI Documentation. \textit{Benchmarks}. \href{https://fastapi.tiangolo.com/benchmarks/}{Link}
    \item DeCandia, G., et al. (2007). \textit{Dynamo: Amazon's Highly Available Key-value Store}. ACM SIGOPS Operating Systems Review, 41(6), 205-220.
    \item Kleppmann, M. (2017). \textit{Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems}. O'Reilly Media, Inc.
    \item This article was translated, edited and written in collaboration with AI. If you find any inconsistencies or have suggestions for improvement, please don't hesitate to open an issue in our GitHub repository at \href{https://github.com/asanchezyali/social-media-posts}{github} or reach out directly.
\end{itemize}

\section{Explore My Other Posts}
\vspace{10pt}
\begin{tikzpicture}
  \fill[color=terminalBg, rounded corners=5pt] (0,0) rectangle (\textwidth,-5);
  \pgfmathsetmacro{\availableWidth}{\textwidth-4cm}
  \begin{scope}
    \node[text=accentColor, font=\Large\bfseries, anchor=north west] at (0.5cm,-0.5cm) {Enjoyed This Content?};
    \node[text=primaryColor, font=\normalsize, anchor=north west] at (0.5cm,-1.2cm) {Don't miss my previous post about:};
    \node[text=secondaryColor, font=\large\bfseries, anchor=north west, text width=\availableWidth] at (0.5cm,-1.9cm) {\color{accentColor}Python Generators: \color{primaryColor}Elegant, Memory-Efficient Iterations};
    \node[text=secondaryColor, font=\small, text width=\availableWidth, anchor=north west] at (0.5cm,-3.1cm) {
      Discover how Python Generators can help you process large datasets efficiently,
      create elegant data pipelines, and write cleaner code with minimal memory footprint.
    };
  \end{scope}
  \node[anchor=center] at ({\textwidth-1.5cm}, {-2.5cm}) {
    \qrcode[height=2.5cm]{https://www.linkedin.com/feed/update/urn:li:activity:7318256898057621504/}
  };
\end{tikzpicture}
\vspace{5pt}

\clearpage
\thispagestyle{empty}
\finalpagecontents

\end{document}

